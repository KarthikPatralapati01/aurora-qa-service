# Aurora Natural-Language Q&A Service  
A lightweight questionâ€“answering API that allows users to ask natural-language questions about Aurora member messages.  
The service semantically indexes all messages from Auroraâ€™s public API, stores embeddings in Pinecone, and uses OpenAI to generate accurate, context-aware answers.

##LOOM VIDEO Link: https://www.loom.com/share/30a1a99f6feb4a5dbe0cba4691714a53

## ğŸ“Œ Overview  
This project implements a production-ready **semantic search + LLM reasoning** pipeline.  
Given any natural-language query such as:

- â€œWhen is Layla planning her trip to London?â€  
- â€œHow many cars does Vikram Desai have?â€  
- â€œWhat are Amiraâ€™s favorite restaurants?â€

The system retrieves relevant member messages from Pinecone, constructs contextual evidence, and generates a concise answer using OpenAI.

---

## ğŸš€ Live Demo  
Swagger Docs:  
```
https://<your-render-url>/docs
```

Ask Questions Through `/ask` Endpoint:  
```
GET https://<your-render-url>/ask?question=YOUR_QUESTION
```

---

## ğŸ“‚ Project Structure
```
â”œâ”€â”€ main.py               # Main FastAPI service
â”œâ”€â”€ inspect_data.py       # Script to analyze dataset anomalies
â”œâ”€â”€ requirements.txt      # Runtime dependencies
â””â”€â”€ .gitignore            # Repo ignore list
```

---

## ğŸ§  Architecture

### High-Level Flow
```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Aurora Public API (/messages)  
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚ Fetch messages (startup)
                                â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ OpenAI Embedding Model   â”‚
                  â”‚ text-embedding-3-small   â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚ Generate semantic vectors
                                 â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ Pinecone Vector DB   â”‚
                     â”‚ (aurora-messages)    â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚ Store & index embeddings
                                  â”‚
                                  â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ FastAPI `/ask` Endpoint                                    â”‚
       â”‚ 1. Embed question                                          â”‚
       â”‚ 2. Retrieve top-k matches from Pinecone                    â”‚
       â”‚ 3. Build context string                                    â”‚
       â”‚ 4. Generate answer using OpenAI (gpt-4o-mini)              â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                             â”‚ JSON Answer Outputâ”‚
                             â”‚ { "answer": ... } â”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ How It Works

### 1. **Fetch Messages**
On application startup:

- The service calls the Aurora `/messages` API.
- Extracts all message text + user names.

### 2. **Embed Messages**
Each message is transformed into a semantic vector using:

```
text-embedding-3-small
```

### 3. **Store in Pinecone**
Vectors are upserted into the Pinecone index:

- dimension: **1536**
- metric: **cosine**
- type: **serverless**

### 4. **Answer Questions**
Users call:

```
GET /ask?question=...
```

Process:

1. Embed the question.
2. Query Pinecone for the top 5 similar messages.
3. Build contextual evidence.
4. Use GPT-4o-mini to generate the final answer.

### 5. **Inference Logic**
The model is instructed to:

- Use context responsibly  
- Give partial answers when possible  
- Avoid hallucination  
- Acknowledge missing details  
- Provide the best available reasoning  

Example:

**Q:** â€œHow many cars does Vikram Desai have?â€  
**A:** â€œVikram mentioned a car, but the messages do not specify how many he owns.â€

---

## ğŸ§ª Example Queries

### Query:
```
GET /ask?question=When is Layla planning her trip to London?
```

### Possible Answer:
```
Layla mentioned planning a trip, but there is no information about a trip to London.
```


### Query:
```
GET /ask?question=How many cars does Vikram Desai have?
```

### Possible Answer:
```
Vikram mentioned a car, but the messages do not specify how many he owns.
```

---

## ğŸ” Dataset Analysis (Anomalies & Insights)

A manual and scripted inspection of all 100 messages reveals:

### âœ… Observed Patterns
- Messages are short and action-oriented (booking, scheduling, requests).
- Multiple members have similar travel-related tasks.
- Most messages follow a consistent structure:  
  `"user_name": "...", "message": "...â€œ`

### âš ï¸ Detected Anomalies
1. **Inconsistent Name Formatting**  
   - Some names include apostrophes (e.g., *Lily O'Sullivan*).  
   - Others include Unicode characters (e.g., *Layla Kawaguchi*).  
   This requires consistent string handling.

2. **Messages Without Clear Intent**  
   - A few messages lack verbs or context (â€œNext Tuesday please.â€)

3. **Duplicate Intent Across Users**  
   - Multiple users request similar tasks (hotel, flights, car pickup).  
   Useful for clustering but can confuse naive search.

4. **Ambiguity**  
   - Some messages imply actions (like owning a car) but do not provide explicit counts or details.

5. **No explicit dates or structured fields**  
   - All time expressions are free-text (â€œnext Mondayâ€, â€œfirst week of Decemberâ€).

These insights help refine both semantic search and answer generation.

---

## ğŸ› ï¸ Technologies Used
| Component | Purpose |
|----------|---------|
| **FastAPI** | API layer |
| **OpenAI GPT-4o-mini** | Answer generation |
| **OpenAI text-embedding-3-small** | Vector embeddings |
| **Pinecone Serverless** | Semantic search index |
| **Render** | Deployment |
| **Python 3.10+** | Runtime |

---

## ğŸš€ Deployment on Render

- Create a Web Service  
- Point to this repo  
- Use start command:  
```
uvicorn main:app --host 0.0.0.0 --port $PORT
```
- Add environment variables:
  - `OPENAI_API_KEY`
  - `PINECONE_API_KEY`
  - `PINECONE_ENVIRONMENT`
  - `PINECONE_INDEX`

---

## ğŸ“œ API Endpoints

### **GET /**
Redirects to Swagger UI.

### **GET /ask**
Ask a question.

**Query Parameter:**  
```
question: string (required)
```

**Response:**  
```json
{
  "answer": "..."
}
```

---

## ğŸ“ Future Improvements

- Add re-ranking layer for higher accuracy  
- Support conversation history  
- Add structured extraction mode  
- Add message clustering for faster retrieval  
- Build UI chatbot interface  



---

## ğŸ“§ Contact  
**Venkata Karthik Patralapati**  
Email: venkatakarthik804@gmail.com  


